---
title: "determine-top-performers-task2"
author: "Maria Diaz"
date: "2023-08-30"
output: html_document
---


## Overview
  
In order to declare top-performers for a DREAM challenge, we need to assess if there are any "tied" methods, that is, methods that are not substantially different in performance. We determine this by using a bootstrapping (sampling with replacement) approach to determining how a submission would score in different scenarios (that is - when only considering re-sampled sets of the values to be predicted). Specifically, we sample with replacement all of the submitted predictions and the goldstandard, then score those prediction files. We repeat this for at total of 1000-10000 samples to obtain a distribution of scores for each participant. We then calculate a Bayes factor relative to the best-scoring method, to see if any of the other methods are within a certain threshold. Smaller Bayes factors indicate more similar performance while larger Bayes factors indicate more disparate performance. We use a Bayes factor of 3 as a cutoff to indicate a tie. 

## Setup

First, we import the packages needed for data manipulation.  Afterward, we retrieve the predictions and goldstandard files, as well as set a seed (so that the resampling results are reproducible).

#### Packages

```{r message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(yardstick))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(readr))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(rcompanion))

synapseclient <- reticulate::import('synapseclient')
syn <- synapseclient$Synapse()
syn$login(silent = TRUE)

set.seed(98109)
```

#### Helper Functions

Querying a Synapse table of submissions will return `submitterid` as either a user ID or team ID (so, an integer).  The following function will return a username or team name based on the ID, for easier identification and more comprehensible plotting. Additionally, `computeBayesFactor()` from the `challengescoring` package is outdated, so redefining an updated function here.


```{r echo=TRUE, message=FALSE, warning=FALSE}
get_name <- function(id) {
  name <- tryCatch({
    syn$getUserProfile(id)$userName
  }, error = function(err) {
    syn$getTeam(id)$name
  })
  name
}

computeBayesFactor <- function(bootstrapMetricMatrix,
                               refPredIndex,
                               invertBayes){
  
  M <- as.data.frame(bootstrapMetricMatrix - bootstrapMetricMatrix[,refPredIndex])
  K <- apply(M ,2, function(x) {
    k <- sum(x >= 0)/sum(x < 0)
    
    # Logic handles whether reference column is the best set of predictions.
    if(sum(x >= 0) > sum(x < 0)){
      return(k)
    }else{
      return(1/k)
    }
  })
  K[refPredIndex] <- 0
  if(invertBayes == T){K <- 1/K}
  return(K)
}
```

#### Goldstandard Files

```{r echo=TRUE, message=FALSE, warning=FALSE}
gold <- read_tsv(syn$get("syn52069274")$path)
head(gold)
```
#### Prediction Files

Participants are allowed 1 scored submissions, where we will only consider the best-performing one for final evaluation. Establishing a rank for each submission.

```{r echo=TRUE, message=FALSE, warning=FALSE}
query <- syn$tableQuery(
  "SELECT
    submitterid,
    accuracy,
    prediction_fileid
  FROM syn52141680
  WHERE
    status = 'ACCEPTED'
    AND submission_status = 'SCORED'
    AND accuracy IS NOT NULL
    GROUP BY submitterid,prediction_fileid
    ORDER BY MAX(accuracy) DESC
  ")$asDataFrame()

query <- query %>%
  distinct(submitterid, .keep_all = TRUE)

# Replace IDs with usernames/team names.
query$submitterid <- as.character(query$submitterid)
team_names <- sapply(query$submitterid, function(sub) {
  get_name(sub)
})

query$submitterid <- team_names 
# Drop row.names for easier table reading.
row.names(query) <- NULL

kable(query)

```
## Bootstrap Submissions

Next, we read in the predictions files and combine them together (with the goldstandard) into a single data frame. This will make bootstrapping easier.

```{r echo=TRUE, message=FALSE, warning=FALSE}

pred_filenames <- lapply(query$prediction_fileid, function(id){
  syn$get(id)$path
})
names(pred_filenames) <- team_names

submissions <- lapply(names(pred_filenames), function(team) {
  read_tsv(pred_filenames[[team]]) %>%
    select(Participant_ID, Disease_Name) %>% 
    rename(!!team := Disease_Name) 
}) %>% 
  purrr::reduce(left_join, by="Participant_ID") %>%
  slice(match(gold$Participant_ID, Participant_ID)) %>%
  left_join(gold, by="Participant_ID") %>%
  rename(gold = Disease_Name)   

kable(head(submissions))
```


Now we will bootstrap the predictions and the goldstandard 1 time to confirm that the results are as expected. The scoring function is taken directly from the original score code and has been rewritten in R. We only have 1 iteration so we will not use a sampling technique until we run this with many iterations.

```{r echo=TRUE}
N <- 1
bs_indices <- matrix(1:nrow(gold), nrow(gold), N)

boot_test <- sapply(names(pred_filenames), function(team){
  apply(bs_indices, 2, function(ind) {
    sum(ifelse(submissions$gold[ind] == submissions[[team]][ind], 1, 0)) / length(submissions[[team]][ind])
  })

})
```

```{r}
boot_test
```
Now we will bootstrap the predictions and the goldstandard 1000 times.  This will produce a matrix of 1000 scores per submission.

```{r echo=TRUE, message=FALSE, warning=FALSE}
N <- 1000
bs_indices <- matrix(1:nrow(gold), nrow(gold), N) %>%
  apply(2, sample, replace = TRUE) 

boot <- sapply(names(pred_filenames), function(team){
  apply(bs_indices, 2, function(ind) {
    sum(ifelse(submissions$gold[ind] == submissions[[team]][ind], 1, 0)) / length(submissions[[team]][ind])
  })

})

```


## Compute and Plot Bayes Factor

For this analysis, we will use the top-performing model as the reference prediction. As a reminder, we will use a Bayes factor of 3 as a cutoff to indicate a tie.

```{r echo=TRUE, message=FALSE, warning=FALSE}
bayes <- computeBayesFactor(boot, refPredIndex = 1, invertBayes = FALSE) %>%
  as_tibble(rownames = "submission") %>%
  rename(bayes = value)
```

## Comparing Models to the Baseline 

One of the requirements to being a top-performer is that it must do better than the baseline - it cannot be tied.  To analyze this, we will now use the baseline model as the reference prediction when computing the Bayes factor. You will need to view your bayes output in the cell above to determine the numeric value of the refPredIndex variable. Enter the index of the row in the bayes output that represents your baseline model.

```{r echo=TRUE, message=FALSE, warning=FALSE}
bayes.ref <- computeBayesFactor(boot, refPredIndex = 7, invertBayes = FALSE) %>%
  as_tibble(rownames = "submission") %>%
  rename(bayes = value)
```


## Plot It All Together

```{r echo=FALSE, message=FALSE}
plot.auc <- boot %>%
  as_tibble() %>%
  tidyr::gather(submission, bs_score) %>%
  left_join(bayes) %>%
  mutate(submission = case_when(
    submission == "Preterm Birth - Vaginal Microbiome Organizers" ~ "Challenge Organizers",
    submission == "Aagaard Lab - Baylor College of Medicine - Texas Childrens Hospital " ~ "Aagaard Lab - BCM - Texas Childrens",
    submission == "Benos Team for DREAM challenge on Preterm Birth" ~ "Benos Team",
    TRUE ~ submission
 )) %>%
  mutate(bayes_category=case_when(
    submission == "Challenge Organizers" ~ "Baseline Model",
    submission == "AI4knowledgeLAB" ~ "Top Performers",
    bayes == 0 ~ "Top Performers",
    bayes <= 20 ~ "Bayes Factor ≤20",
    bayes >= 20 ~ "Bayes Factor >20")) %>%
  ggplot(aes(
    x = forcats::fct_reorder(submission, bs_score, .fun = mean),
    y = bs_score,
    color = bayes_category
  )) +
  geom_boxplot(lwd = 1.2, fatten = 1) +
  theme_bw() +
  scale_color_manual(values = c(
    "Top Performers" = "#FFBF00", 
    'Bayes Factor ≤20' = '#219EE6', 
    "Bayes Factor >20" = "#B6B5B3",
    "Baseline Model" = "#C74EDA"),
    name = NULL) +
  coord_flip() +
  labs(x="Team", y="Bootstrapped AUC-ROC\n(n=1000)") +
  theme(
    axis.text.y.left = element_text(size = 19),
    axis.text.x.bottom = element_text(size = 18),
    text = element_text(size = 16),
    legend.text = element_text(size = 19),
    legend.position = c(0.15, 0.92),
    legend.background = element_rect(linetype = "solid", color = "black"))

plot.bayes.top <- bayes %>% 
  mutate(bayes_category=case_when(
    submission == "Preterm Birth - Vaginal Microbiome Organizers" ~ "Baseline Model",
    submission == "AI4knowledgeLAB" ~ "Top Performer",
    bayes == 0 ~ "Top Performer",
    bayes <= 20 ~ "Bayes Factor ≤20",
    bayes >= 20 ~ "Bayes Factor >20")) %>% 
  ggplot(aes(submission, bayes, fill=bayes_category)) + 
  geom_bar(stat='identity') + coord_flip(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = 2, lwd = 1.2) +
  theme_classic() + 
  scale_x_discrete(limits=names(sort(colMeans(boot)))) + 
  scale_fill_manual(values = c(
    "Top Performer" = "#FFBF00", 
    'Bayes Factor ≤20' = '#219EE6', 
    "Bayes Factor >20" = "#B6B5B3",
    "Baseline Model" = "#C74EDA")) +
  theme(legend.position = "none") +
  theme(
    text = element_text(size = 16),
    axis.text.x.bottom = element_text(size = 18),
    axis.title.y=element_blank(), 
    axis.text.y=element_blank()) + 
  labs(y="Bayes Factor\n(Top Performer=UWisc-Madison)")

plot.bayes.ref <- bayes.ref %>% 
  mutate(bayes_category=case_when(
    submission %in% c("UWisc-Madison", "AI4knowledgeLAB") ~ "Top Performer",
    bayes == 0 ~ "Baseline Model",
    bayes<=20 ~ "Bayes Factor ≤20",
    bayes>=20 ~ "Bayes Factor >20")) %>% 
  ggplot(aes(submission, bayes, fill=bayes_category)) + 
  geom_bar(stat='identity') + coord_flip(ylim = c(0, 20)) + 
  geom_hline(yintercept = 3, linetype = 2, lwd = 1.2) +
  theme_classic() + 
  scale_x_discrete(limits=names(sort(colMeans(boot)))) + 
  scale_fill_manual(values = c(
    "Top Performer" = "#FFBF00", 
    'Bayes Factor ≤20' = '#219EE6', 
    "Bayes Factor >20" = "#B6B5B3",
    "Baseline Model" = "#C74EDA")) +
  theme(legend.position = "none") +
  theme(
    text = element_text(size = 16),
    axis.text.x.bottom = element_text(size = 18),
    axis.title.y=element_blank(), 
    axis.text.y=element_blank()) + 
  labs(y="Bayes Factor\n(Baseline Model)")

ggsave(
  file="sc1-bf.svg",
  plot=gridExtra::grid.arrange(plot.auc, plot.bayes.top, plot.bayes.ref, ncol = 3, widths = c(3, 1, 1)),
  width = 24,
  height = 18.6
)
```
