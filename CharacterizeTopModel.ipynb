{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b011d46b-6c34-4bb6-b49b-34860839e0ed",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook will analyze the predictions of specific models for classification accuracy on subtypes, confusion matrix, and feature importances for the [RARE-X Challenge](https://www.synapse.org/#!Synapse:syn51198355/wiki/621435) Task 2 submissions\n",
    "\n",
    "September 2023\n",
    "\n",
    "Jake Albrecht\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b84c8c-8c05-4ee9-aa2a-58131d30d0c1",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4763d8-66b3-4eb9-a59d-894593284d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc50c2a-de2f-4955-b1c0-e2e3951db391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import synapseclient\n",
    "syn = synapseclient.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db49ff7-a321-496b-ab30-0f1886d93994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_name(id):\n",
    "    try:\n",
    "        name = syn.getUserProfile(id).userName\n",
    "    except synapseclient.core.exceptions.SynapseHTTPError:\n",
    "        name = syn.getTeam(id).name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40081522-8dbe-43fe-b793-8c8e8cecff17",
   "metadata": {},
   "source": [
    "## Get ground truth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12510601-63ca-4bd3-80df-d6203a0d35f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gold  = pd.read_csv(syn.get(\"syn52069274\").path,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12579153-8b4d-425b-8635-a378a103fcf5",
   "metadata": {},
   "source": [
    "## Get predictions, top submission from each team:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06d95b-93fc-40a8-bc64-0a9267aefdb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qu = syn.tableQuery(\"SELECT\\\n",
    "    submitterid,\\\n",
    "    accuracy,\\\n",
    "    prediction_fileid\\\n",
    "  FROM syn52141680\\\n",
    "  WHERE\\\n",
    "    status = 'ACCEPTED'\\\n",
    "    AND submission_status = 'SCORED'\\\n",
    "    AND accuracy IS NOT NULL\\\n",
    "    AND id <> 9738335\\\n",
    "    GROUP BY submitterid,prediction_fileid\\\n",
    "    ORDER BY MAX(accuracy) DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1fd5aa-0ac9-4be0-ac58-3c5b4a472c37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_soln = qu.asDataFrame().groupby('submitterid').head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054dd7f9-9ecd-4e62-8db5-d9af55e54bc0",
   "metadata": {},
   "source": [
    "## Score individual submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1001de6-795d-43ec-8a3f-4bc0d698213a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for ix in range(0,3):\n",
    "    teamname = get_name(top_soln.submitterid.values[ix])\n",
    "    pred = pd.read_csv(syn.get(top_soln.prediction_fileid.values[ix]).path,sep='\\t')\n",
    "    scoresheet = pd.merge(pred,gold,on='Participant_ID',suffixes=('_pred','_gt'))\n",
    "    scoresheet['Match'] = scoresheet.Disease_Name_pred == scoresheet.Disease_Name_gt\n",
    "    scores.append(scoresheet.groupby('Disease_Name_gt').agg({'Match':['mean']}).rename(columns={'Match':teamname}))\n",
    "    \n",
    "    cm = confusion_matrix(scoresheet.Disease_Name_gt, scoresheet.Disease_Name_pred, labels=scoresheet.Disease_Name_gt.unique())\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                   display_labels=scoresheet.Disease_Name_gt.unique())\n",
    "    disp.plot()\n",
    "    plt.title(teamname)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(f'ConfusionMatrix_{teamname}.png',bbox_inches='tight')\n",
    "scores.append(scoresheet.groupby('Disease_Name_gt').agg({'Match':['count']}).rename(columns={'Match':'Cases'}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467c1da-5a3b-4acd-b72a-4d099080dbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat(scores,axis=1).to_csv('Label_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43d22e5-caf0-4cd3-9e8b-5e29ae7c9230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aed67b-9413-4e84-8a9d-c4d9f2138b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
